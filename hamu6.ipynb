{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gogo\n",
      "Connector to MYSQL Server: ggnas.synology.me SUCCESS\n",
      "(1, '1101', '台泥')\n",
      "Fri Mar 31 18:49:27 2017:\n",
      "1101 in 2017/3 OK\n",
      "\n",
      "2017-03-31 18:49:29.938191\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "crawl 個股 is Done\n"
     ]
    }
   ],
   "source": [
    "from yahoo_finance import Share\n",
    "import requests\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import sqlite3 as lite\n",
    "from shutil import copyfileobj\n",
    "import smtplib\n",
    "import mimetypes\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email import encoders\n",
    "from email.message import Message\n",
    "from email.mime.audio import MIMEAudio\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.text import MIMEText\n",
    "from datetime import datetime , date ,timedelta\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "#from time import sleep\n",
    "import time\n",
    "import mysql.connector\n",
    "\n",
    "#define max stock id\n",
    "max_stock_id = 1000\n",
    "\n",
    "#payload data for twse\n",
    "payload={}\n",
    "dt_str = []\n",
    "#gmail setting\n",
    "emailfrom = \"gghammer@gmail.com\"\n",
    "emailto = \"gghammer@gmail.com\"\n",
    "#fileToSend = \"daily.xlsx\"\n",
    "username = \"gghammer\"\n",
    "password = \"ggpudin81161\"\n",
    "\n",
    "def conn_mysql():\n",
    "    try:\n",
    "        #server = '192.168.0.110' \n",
    "        server = 'ggnas.synology.me'\n",
    "        cnx = mysql.connector.connect(user='stock', password='stock168',host= server,database='stock')  \n",
    "        print(\"Connector to MYSQL Server:\",server,\"SUCCESS\")\n",
    "        return cnx \n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))   \n",
    "        try:\n",
    "            #server = 'ggnas.synology.me'\n",
    "            server = '192.168.0.110'\n",
    "            cnx = mysql.connector.connect(user='stock', password='stock168',host= server,database='stock')   \n",
    "            print(\"Connector to MYSQL Server:\",server,\"SUCCESS\")\n",
    "            return cnx \n",
    "        except OSError as err:\n",
    "            print(\"OS error: {0}\".format(err))\n",
    "            print(\"Connector to MYSQL Server FAIL\") \n",
    "    \n",
    "def send_to_gmail(source,attach_name):    \n",
    "    #save to xlsx file\n",
    "    twse = pandas.read_csv(source,encoding = \"big5\",header=1)    \n",
    "    writer = pandas.ExcelWriter(attach_name, engine='xlsxwriter')\n",
    "    twse.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.save()\n",
    "\n",
    "    #gmail send \n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"From\"] = emailfrom\n",
    "    msg[\"To\"] = emailto\n",
    "    today = date.today()    \n",
    "    #msg[\"Subject\"] = \"哈墨投顧日報 \"+currenttime.strftime('%Y-%m-%d')\n",
    "    msg[\"Subject\"] = \"哈墨投顧日報 \"+str(today)    \n",
    "    msg.preamble = \"help I cannot send an attachment to save my life\"\n",
    "\n",
    "    ctype, encoding = mimetypes.guess_type(attach_name)\n",
    "    if ctype is None or encoding is not None:\n",
    "        ctype = \"application/octet-stream\"\n",
    "\n",
    "    maintype, subtype = ctype.split(\"/\", 1)\n",
    "\n",
    "    if maintype == \"text\":\n",
    "        fp = open(attach_name)\n",
    "        # Note: we should handle calculating the charset\n",
    "        attachment = MIMEText(fp.read(), _subtype=subtype)\n",
    "        fp.close()\n",
    "    elif maintype == \"image\":\n",
    "        fp = open(attach_name, \"rb\")\n",
    "        attachment = MIMEImage(fp.read(), _subtype=subtype)\n",
    "        fp.close()\n",
    "    elif maintype == \"audio\":\n",
    "        fp = open(attach_name, \"rb\")\n",
    "        attachment = MIMEAudio(fp.read(), _subtype=subtype)\n",
    "        fp.close()\n",
    "    else:\n",
    "        fp = open(attach_name, \"rb\")\n",
    "        attachment = MIMEBase(maintype, subtype)\n",
    "        attachment.set_payload(fp.read())\n",
    "        fp.close()\n",
    "        encoders.encode_base64(attachment)\n",
    "    attachment.add_header(\"Content-Disposition\", \"attachment\", filename=attach_name)\n",
    "    msg.attach(attachment)\n",
    "\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com:587\")\n",
    "    server.starttls()\n",
    "    server.login(username,password)\n",
    "    server.sendmail(emailfrom, emailto, msg.as_string())\n",
    "    server.quit()\n",
    "    print(\"Send Gmail done\")\n",
    "\n",
    "def crawl_stock_id(name):  \n",
    "    #catch payload \n",
    "    res = requests.post('http://www.tse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_d.php#')\n",
    "    res.encoding = 'big5'\n",
    "\n",
    "    #find key & Encryption \n",
    "    soup = BeautifulSoup(res.text, 'html.parser') \n",
    "\n",
    "    for inp in soup.select('input'):\n",
    "        if 'hidden' in inp.get('type'): \n",
    "            payload[inp.get('name')] = base64.b64encode(inp.get('value').encode('utf-8')) \n",
    "        \n",
    "    #download csw file        \n",
    "    res2 = requests.post('http://www.tse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_print.php?language=ch&save=csv',data = payload ,stream = True)\n",
    "\n",
    "    #save to twse.csv \n",
    "    f = open(name,'wb')\n",
    "    copyfileobj (res2.raw,f)\n",
    "    f.close()  \n",
    "    \n",
    "    \n",
    "def crawl(target):  \n",
    "    \n",
    "    \n",
    "    #catch payload \n",
    "    res = requests.post('http://www.tse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_d.php#')\n",
    "    res.encoding = 'big5'\n",
    "\n",
    "    #find key & Encryption \n",
    "    soup = BeautifulSoup(res.text, 'html.parser') \n",
    "\n",
    "    #get & translate date \n",
    "    dt = soup.select('input')[2].get('value')\n",
    "    dt = dt.replace(dt[0:3], str(int(dt[0:3])+ 1911))\n",
    "    dt = dt.replace(dt[4:5],'-')\n",
    "    dt_str = dt.split(' ')\n",
    "\n",
    "    for inp in soup.select('input'):\n",
    "        if 'hidden' in inp.get('type'): \n",
    "            payload[inp.get('name')] = base64.b64encode(inp.get('value').encode('utf-8')) \n",
    "        \n",
    "    #download csw file        \n",
    "    res2 = requests.post('http://www.tse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_print.php?language=ch&save=csv',data = payload ,stream = True)\n",
    "\n",
    "    #save to twse.csv \n",
    "    f = open('twse.csv','wb')\n",
    "    copyfileobj (res2.raw,f)\n",
    "    f.close()  \n",
    "\n",
    "    #read csw to pandas \n",
    "    twse = pandas.read_csv('twse.csv',encoding = \"big5\",header=1)\n",
    "\n",
    "    with lite.connect(target) as conn:   \n",
    "        for i in range(0,max_stock_id):\n",
    "            col = twse.iloc[i]\n",
    "            col = col.tolist()\n",
    "            stock_id = col[0]\n",
    "            if len(stock_id)>10 :\n",
    "                break\n",
    "            else:    \n",
    "                data = dt_str + col\n",
    "                conn.execute('INSERT INTO 指標 (日期,代號,名稱,本益比,殖利率,股價淨值比) VALUES (?,?,?,?,?,?);', data)\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"crawl 指標 is Done\")\n",
    "    \n",
    "def update_stock_id(name):    \n",
    "\n",
    "    crawl_stock_id('temp.csv')\n",
    "    #read csw to pandas \n",
    "    twse = pandas.read_csv('temp.csv',encoding = \"big5\",header=1)\n",
    "    \n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor()    \n",
    "    for i in range(0,max_stock_id):\n",
    "        col = twse.iloc[i]\n",
    "        col = col.tolist()\n",
    "        del col[2:5]   \n",
    "        stock_id = col[0]\n",
    "        stock_name = col[1]\n",
    "        if len(stock_id)>10:\n",
    "            break\n",
    "        else:   \n",
    "            cursor.execute (\"UPDATE 股票代號 SET 代號='%s',名稱='%s' WHERE ID='%d'\" % (stock_id,stock_name,i+1))\n",
    "           \n",
    "    conn.commit()\n",
    "    conn.close()  \n",
    "    \n",
    "    os.remove(\"temp.csv\")\n",
    "    print(\"Stock ID update success !\")\n",
    "    \n",
    "def del_sql_lib():\n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DROP TABLE 股票代號\")   \n",
    "    cursor.execute(\"DROP TABLE 股價\") \n",
    "    cursor.execute(\"CREATE TABLE 指標\")\n",
    "    cursor.execute(\"CREATE TABLE 營收\")    \n",
    "    \n",
    "    \n",
    "def create_sql_lib(name):    \n",
    "    #create sqlite lib\n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"CREATE TABLE 股票代號 (\n",
    "                                            ID   INT(12) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n",
    "                                            代號 VARCHAR(10)CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "                                            名稱 VARCHAR(10)CHARACTER SET utf8 COLLATE utf8_general_ci )\"\"\")                  \n",
    "    cursor.execute(\"\"\"CREATE TABLE 股價 (\n",
    "                                        ID   INT(12) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n",
    "                                        日期 DATE,\n",
    "                                        代號 INT(12),\n",
    "                                        名稱 VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci, \n",
    "                                        開盤價 FLOAT,\n",
    "                                        收盤價 FLOAT,\n",
    "                                        漲跌 FLOAT,\n",
    "                                        漲跌百分比 FLOAT,\n",
    "                                        最高 FLOAT,\n",
    "                                        最低 FLOAT,\n",
    "                                        日量 INT(12),\n",
    "                                        均線50 FLOAT,\n",
    "                                        均線200 FLOAT)\"\"\")          \n",
    "    \n",
    "    cursor.execute(\"\"\"CREATE TABLE 指標 (\n",
    "                                         ID   INT(12) NOT NULL AUTO_INCREMENT PRIMARY KEY,       \n",
    "                                         日期 DATE ,\n",
    "                                         代號 INT(12),\n",
    "                                         名稱 VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci, \n",
    "                                         本益比 FLOAT,\n",
    "                                         殖利率 FLOAT,\n",
    "                                         股價淨值比 FLOAT)\"\"\")    \n",
    "    cursor.execute(\"\"\"CREATE TABLE 營收 (\n",
    "                                         ID   INT(12) NOT NULL AUTO_INCREMENT PRIMARY KEY,       \n",
    "                                        日期 DATE,\n",
    "                                        代號 INT(12),\n",
    "                                        名稱 VARCHAR(8) CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "                                        EPS FLOAT,\n",
    "                                        月營收 FLOAT,\n",
    "                                        季營收 FLOAT,\n",
    "                                        年營收 FLOAT,\n",
    "                                        配息 FLOAT,\n",
    "                                        配股 FLOAT)\"\"\")\n",
    "    \n",
    "    print (\"MySQL LIB created successfully\")  \n",
    "    \n",
    "    \n",
    "    crawl_stock_id('temp.csv')\n",
    "    \n",
    "    #read csw to pandas \n",
    "    twse = pandas.read_csv('temp.csv',encoding = \"big5\",header=1)\n",
    "\n",
    "    #update to sqlite file \n",
    "    for i in range(0,max_stock_id):\n",
    "        col = twse.iloc[i]\n",
    "        col = col.tolist()\n",
    "        del col[2:5]\n",
    "        if len(col[0]) >10:\n",
    "            break\n",
    "        else:    \n",
    "            cursor.execute(\"INSERT INTO 股票代號 (代號,名稱) VALUES ('%s','%s')\"%(col[0],col[1]))   \n",
    "    conn.commit()           \n",
    "    conn.close()      \n",
    "\n",
    "    \n",
    "    os.remove(\"temp.csv\")\n",
    "    print (\"Stock ID created successfully\") \n",
    "    \n",
    "    \n",
    "def getStock_history(id,start,end):\n",
    "    stock = Share(str(id)+'.TW')\n",
    "    data = stock.get_historical(start, end)\n",
    "    return data\n",
    "\n",
    "\n",
    "def crawl_history(target):     \n",
    "    today = date.today() #todays date \n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor(buffered = True)\n",
    "    cursor.execute(\"SELECT * FROM 股票代號\") \n",
    "    for i in range(0,max_stock_id):             \n",
    "        sql = cursor.fetchone()\n",
    "        print(sql)\n",
    "        if sql:    \n",
    "            try:\n",
    "                #print(sql[2])\n",
    "                stock = getStock_history(sql[1],'2008-01-01',str(today))    \n",
    "                for i in range(0,len(stock)):                            \n",
    "                    data = stock[i]\n",
    "                    #print(data)\n",
    "                    if data['Date']:\n",
    "                        stock_date = data['Date']\n",
    "                    if data['Open']:  \n",
    "                        stock_open = data['Open']\n",
    "                    if data['High']:                         \n",
    "                        stock_high = data['High']\n",
    "                    if data['Low']:                         \n",
    "                        stock_low = data['Low']\n",
    "                    if data['Close']:         \n",
    "                        stock_close = data['Close']\n",
    "                    if data['Volume']:\n",
    "                        stock_volume = (int(data['Volume'])/1000)\n",
    "                    if int(stock_volume):      \n",
    "                        #sql_list = [stock_date]+[sql[0]]+[sql[1]]+[stock_open]+[stock_close]+[stock_high]+[stock_low]+[stock_volume]\n",
    "                        cursor2 = conn.cursor(buffered = True)\n",
    "                        cursor2.execute(\"INSERT INTO 股價 (日期,代號,名稱,開盤價,收盤價,最高,最低,日量) VALUES ('%s','%s','%s','%s','%s','%s','%s','%d')\"%(stock_date,sql[1],sql[2],stock_open,stock_high,stock_low,stock_close,stock_volume))                     \n",
    "                conn.commit()    \n",
    "                print(datetime.now())  \n",
    "            except OSError as err:\n",
    "                print(\"OS error: {0}\".format(err))\n",
    "                print(\"Not support ID =\",sql[0])            \n",
    "    conn.close()    \n",
    "    print(\"Crawl history is done\")\n",
    "    \n",
    "#################個股日成交資訊 #################\n",
    "def getStockCommandOneWithData(fileFolder, year, month, stockID):\n",
    "    fileType = 'csv'\n",
    "    payload = {\n",
    "        'download':str(fileType),\n",
    "        'query_year':str(year),\n",
    "        'query_month':str(month),\n",
    "        'CO_ID':str(stockID),\n",
    "        'query-button':'查詢'\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        url = 'http://www.twse.com.tw/ch/trading/exchange/STOCK_DAY/STOCK_DAYMAIN.php'\n",
    "        encodeMethod = 'big5'\n",
    "            \n",
    "        fileName = str(stockID) + \"_\" + str(year) + \"_\" + str(month) + \".\"+fileType\n",
    "        savePath = fileFolder + fileName\n",
    "            \n",
    "            \n",
    "        res = requests.post(url, data=payload, stream=True)\n",
    "        f = open(savePath, 'wb')\n",
    "        copyfileobj(res.raw, f)\n",
    "        f.close()\n",
    "            \n",
    "            \n",
    "            \n",
    "        #file = open(savePath,\"wb\") #open file in binary mode\n",
    "        #file.write(the_page)\n",
    "        #file.close()\n",
    "            \n",
    "        #webpage = open(savePath, 'r')\n",
    "        #twse = pandas.read_csv(savePath,encoding = \"big5\",header=1)\n",
    "        #newspd = pandas.DataFrame(twse)\n",
    "        #print(newspd)\n",
    "        time.sleep(0.1)\n",
    "        print (\"%s:\" % time.ctime(time.time()))\n",
    "            \n",
    "        print(str(stockID) + ' in ' + str(year) + '/' + str(month) + ' OK')\n",
    "        return fileName\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "        print(str(stockID) + ' Get Data Fail' + ' in ' + str(year) + '/' + str(month) )\n",
    "        return None\n",
    "                \n",
    "    \n",
    "def getStockPERAndYieldByDayWithData(fileFolder, year, month, day):\n",
    "        \n",
    "    url1 = 'http://www.twse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_d.php'\n",
    "    url2 = 'http://www.twse.com.tw/ch/trading/exchange/BWIBBU/BWIBBU_print.php?language=ch&save=csv&save=csv&save=csv'\n",
    "    nYear = year - 1911\n",
    "    \n",
    "    nMonth = str(month)\n",
    "    nDay = str(day)\n",
    "    if month < 10:\n",
    "        \n",
    "        nMonth = '0' + str(month)\n",
    "        \n",
    "    if day < 10:\n",
    "        nDay = '0' + str(day)\n",
    "            \n",
    "    newDateStr = str(nYear)+'/'+str(nMonth)+'/'+str(nDay)\n",
    "    print(newDateStr)\n",
    "        \n",
    "    postOneData = {\n",
    "        'input_date':newDateStr,\n",
    "        'select2':'ALL',\n",
    "        'order':'STKNO',\n",
    "        'login_btn':'(unable to decode value)'\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "            \n",
    "        encodeMethod = 'big5'\n",
    "        payloadData = {}\n",
    "\n",
    "        fileName = str(year) + \"_\" + str(month) + \"_\" + str(day) + \".\" + 'csv'\n",
    "        savePath = fileFolder + fileName\n",
    "\n",
    "        res = requests.post(url1, data=postOneData)\n",
    "        res.encoding = encodeMethod\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        for inp in soup.select('input'):\n",
    "            if 'hidden' in inp.get('type'):\n",
    "                payloadData[inp.get('name')] = base64.b64encode(inp.get('value').encode('utf-8'))\n",
    "        \n",
    "        res2 = requests.post(url2, data=payloadData, stream=True)\n",
    "        f = open(savePath, 'wb')\n",
    "        copyfileobj(res2.raw, f)\n",
    "        f.close()\n",
    "        \n",
    "        webpage = open(savePath, 'r')\n",
    "        twse = pandas.read_csv(savePath,encoding = \"big5\", header=1, names=['證券代號', '證券名稱', '本益比', '殖利率(%)', '股價淨值比'])\n",
    "        newspd = pandas.DataFrame(twse)\n",
    "        \n",
    "        if newspd.columns[0] != '證券代號':\n",
    "            os.remove(savePath)\n",
    "            print(str(year) + '/' + str(month) + '/' + str(day) + ' No Data')\n",
    "            return None\n",
    "        #else:\n",
    "            #print (\"%s:\" % time.ctime(time.time()))\n",
    "            #print(str(year) + '/' + str(month) + '/' + str(day) + ' OK')\n",
    "        \n",
    "        #print(payloadData)\n",
    "            \n",
    "        #webpage = open(savePath, 'r')\n",
    "        #twse = pandas.read_csv(savePath,encoding = \"big5\",header=1)\n",
    "        #newspd = pandas.DataFrame(twse)\n",
    "        #print(newspd)\n",
    "        #time.sleep(0.1)\n",
    "        \n",
    "        return fileName\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "        print(' Get Data Fail' + ' in ' + str(year) + '/' + str(month) + '/' + str(day) )\n",
    "        return None \n",
    "    \n",
    "def crawl_本益比殖利率_by_Day(delta_days):\n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor(buffered = True)     \n",
    "    currenttime = datetime.now() \n",
    "    for i in range(1,delta_days):\n",
    "        dt = currenttime - timedelta( days = i)\n",
    "        filename = getStockPERAndYieldByDayWithData('/Users/gghammer/Desktop/python/database/指標/',int(dt.strftime('%Y')),int(dt.strftime('%m')),int(dt.strftime('%d')))\n",
    "        if filename:           \n",
    "            #read csw to pandas \n",
    "            twse = pandas.read_csv('./database/指標/'+filename,encoding = \"big5\",header=1)  \n",
    "            for i in range(0,max_stock_id):\n",
    "                col = twse.iloc[i]\n",
    "                col = col.tolist()\n",
    "                stock_id = col[0]\n",
    "                stock_pe = round(float2(col[2]),2)\n",
    "                stock_dy = round(float2(col[3]),2)\n",
    "                stock_pbr = round(float2(col[4]),2)\n",
    "                #print(stock_pe,stock_dy,stock_pbr)\n",
    "                if len(stock_id)>10 :\n",
    "                    break\n",
    "                else:    \n",
    "                    cursor.execute(\"INSERT INTO 指標 (日期,代號,名稱,本益比,殖利率,股價淨值比)VALUES ('%s','%d','%s','%f','%f','%f')\"\n",
    "                                    %(dt.strftime('%Y-%m-%d'),int(stock_id),col[1],stock_pe,stock_dy,stock_pbr)) \n",
    "        conn.commit()\n",
    "        print(datetime.now()) \n",
    "    conn.close()\n",
    "    print(\"crawl 指標 is Done\")\n",
    "      \n",
    "def crawl_個股_by_Month(delta_month):\n",
    "    conn = conn_mysql()\n",
    "    cursor = conn.cursor(buffered = True)\n",
    "    cursor.execute(\"SELECT * FROM 股票代號\") \n",
    "    #for i in range(0,max_stock_id):          \n",
    "    for i in range(0,100):          \n",
    "        sql = cursor.fetchone()\n",
    "        print(sql)\n",
    "        if sql:  \n",
    "            currenttime = datetime.now() \n",
    "            for i in range(1,delta_month):\n",
    "                dt = currenttime - timedelta( days = i*(365/12))\n",
    "                stock_id = sql[1]\n",
    "                stock_name = sql[2]\n",
    "                filename = getStockCommandOneWithData('/Users/gghammer/Desktop/python/database/個股/',\n",
    "                                                      int(dt.strftime('%Y')),int(dt.strftime('%m')),stock_id)\n",
    "                if filename:                             \n",
    "                    #read csw to pandas \n",
    "                    twse = pandas.read_csv('./database/個股/'+filename,encoding = \"big5\",skiprows=[0],index_col = False)  \n",
    "                    try: \n",
    "                        for i in range(0,31):\n",
    "                            col = twse.iloc[i]\n",
    "                            col = col.tolist()\n",
    "                            stock_date = col[0]\n",
    "                            stock_volume = int(col[1].replace(\",\",\"\"))\n",
    "                            stock_open = round(float2(col[3]),2)\n",
    "                            stock_high = round(float2(col[4]),2)\n",
    "                            stock_low  = round(float2(col[5]),2)  \n",
    "                            stock_close = round(float2(col[6]),2)\n",
    "                            stock_delta = round(float2(col[7]),2)\n",
    "                            stock_deal = int(col[8].replace(\",\",\"\"))\n",
    "                            if len(stock_id)>10:\n",
    "                                break\n",
    "                            else:   \n",
    "                                cursor.execute(\"INSERT INTO 股價 (日期,代號,名稱,開盤價,收盤價,漲跌,最高,最低,日量)VALUES ('%s','%d','%s','%f','%f','%f','%f','%f','%d')\"\n",
    "                                               %(stock_date,int(stock_id),stock_name,stock_open,stock_close,stock_delta,stock_high,stock_low,stock_volume))\n",
    "                    except:\n",
    "                        print(\"\")\n",
    "            conn.commit()\n",
    "            print(datetime.now()) \n",
    "    conn.close()\n",
    "    print(\"crawl 個股 is Done\")    \n",
    "    \n",
    "def float2(value):\n",
    "    \n",
    "    try:\n",
    "        value = float(value)\n",
    "        return value\n",
    "    except:\n",
    "        return 0.0    \n",
    "            \n",
    "#main   \n",
    "def main(fucntion):\n",
    "    print(\"gogo\")    \n",
    "#    if fucntion == 'create_lib':\n",
    "#    create_sql_lib('stock.sqlite')     \n",
    "#    del_sql_lib()    \n",
    "        \n",
    "#    elif fucntion == 'update_stock_id':conn.commit(\n",
    "#    update_stock_id('stock.sqlite')  \n",
    "    \n",
    "#    elif fucntion == 'crawl':      \n",
    "#        crawl('stock.sqlite')  #target sql file name , para    \n",
    "#    stock = crawl_history('stock.sqlite')  \n",
    "#    crawl_本益比殖利率_by_Day(2)\n",
    "    crawl_個股_by_Month(2)\n",
    "    #sts = getStockPERAndYieldByDayWithData('/Users/gghammer/Desktop/python/',2017,3,20)\n",
    "#    elif fucntion == 'crawl_history':      \n",
    "#        stock = crawl_history('stock.sqlite')   \n",
    "#    elif fucntion == 'report':\n",
    "#        send_to_gmail('twse.csv','daily.xlsx') #source pandas structure , target excel file name        \n",
    "#    else:\n",
    "#        print(' Usag   hamu create_lib          #建立資料庫')\n",
    "#        print('        hamu update_stock_id     #更新股票代號')\n",
    "#        print('        hamu crawl               #爬當日資料')\n",
    "#        print('        hamu crawl               #爬歷史資料')\n",
    "#        print('        hamu report              #透過gmail寄出電子報')\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
